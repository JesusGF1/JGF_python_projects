{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('dogfood').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('dog_food.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(A=4, B=2, C=12.0, D=3, Spoiled=1.0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'Spoiled']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(col(\"Spoiled\").alias(\"label\"),col(\"A\").alias(\"A\"),col(\"B\").alias(\"B\"),col(\"C\").alias(\"C\"),col(\"D\").alias(\"D\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'A', 'B', 'C', 'D']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'A','B','C','D'],\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(df)\n",
    "\n",
    "final_data = output.select(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              label|\n",
      "+-------+-------------------+\n",
      "|  count|                330|\n",
      "|   mean|  0.296969696969697|\n",
      "| stddev|0.45761695964387855|\n",
      "|    min|                0.0|\n",
      "|    max|                1.0|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier,\n",
    "                                       DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier(numTrees = 100)\n",
    "gbt = GBTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train)\n",
    "rfc_model = rfc.fit(train)\n",
    "gbt_model = gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test)\n",
    "rfc_preds = rfc_model.transform(test)\n",
    "gbt_preds = gbt_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-------------+--------------------+----------+\n",
      "|           features|label|rawPrediction|         probability|prediction|\n",
      "+-------------------+-----+-------------+--------------------+----------+\n",
      "| [1.0,1.0,12.0,4.0]|  1.0|   [0.0,77.0]|           [0.0,1.0]|       1.0|\n",
      "|  [1.0,2.0,9.0,1.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [1.0,2.0,9.0,4.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [1.0,3.0,8.0,5.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [1.0,4.0,9.0,3.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [1.0,5.0,8.0,5.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "| [1.0,5.0,8.0,10.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [1.0,6.0,8.0,9.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [1.0,7.0,8.0,4.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [1.0,8.0,8.0,6.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [1.0,9.0,7.0,4.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [1.0,9.0,7.0,5.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|[1.0,10.0,11.0,4.0]|  1.0|   [0.0,77.0]|           [0.0,1.0]|       1.0|\n",
      "|  [2.0,3.0,6.0,9.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "| [2.0,3.0,7.0,10.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "| [2.0,3.0,13.0,1.0]|  1.0|   [0.0,77.0]|           [0.0,1.0]|       1.0|\n",
      "|[2.0,4.0,13.0,10.0]|  1.0|   [0.0,11.0]|           [0.0,1.0]|       1.0|\n",
      "|  [2.0,5.0,7.0,6.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [2.0,5.0,8.0,3.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "|  [2.0,6.0,8.0,8.0]|  0.0|  [215.0,1.0]|[0.99537037037037...|       0.0|\n",
      "+-------------------+-----+-------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC: 0.975\n",
      "RFC: 0.9875\n",
      "GBT: 0.975\n"
     ]
    }
   ],
   "source": [
    "print(f'DTC: {evaluator.evaluate(dtc_preds)}') \n",
    "print(f'RFC: {evaluator.evaluate(rfc_preds)}')\n",
    "print(f'GBT: {evaluator.evaluate(gbt_preds)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
